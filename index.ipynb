{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from calibrate_simulation.calibrate_simulation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calibrate-simulation\n",
    "\n",
    "> A Metamodel-Based General-purpose Calibration Tool for Simulation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package is implementing the metamodel optimization method described in [1]. The aim of this repository is to provide a base sample implementation that can be used to to train a metamodel based on a given sample input â€“ output result set then create an optimization model based on the trained metamodel and finally get candidate input parameters that will generate any given desired output. \n",
    "\n",
    "A simple use case for the module consists of 3 steps: \n",
    "1.\tinitialize the module object, \n",
    "2.\ttrain the metamodel by supplying training and validation datasets\n",
    "3.\t Use optimization model to create candidate input parameters given lower and upper bounds and target output \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install calibrate_simulation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating the optimizer object and initializing the module the user must choose between implemented two metamodel types and two MIP solvers. The metamodel types are:\n",
    "\n",
    "1. Random Forest based metamodel. (not yet implemented)\n",
    "2. Artificial neural network based metamodel. \n",
    "\n",
    "The available MIP solvers for the optimization step are:\n",
    "\n",
    "1. GUROBI solver (To use the GUROBI solver the user hast to provide the necessary licenses).\n",
    "2. Google OR Tools based SCIP solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import numpy as np\n",
    "\n",
    "# Random data for example purposes\n",
    "X_training = np.random.randn(20000,6)\n",
    "X_validation = np.random.randn(5000,6)\n",
    "X_test = np.random.randn(4000,6)\n",
    "\n",
    "Y_training = np.random.randn(20000,9)\n",
    "Y_validation = np.random.randn(5000,9)\n",
    "Y_test = np.random.randn(4000,9)\n",
    "\n",
    "# Initialize the Calibration object \n",
    "optimizer = CalibrateSimulation(OptimizerType.OR_TOOLS)\n",
    "\n",
    "# Train the metamodel \n",
    "optimizer.train_model(X_training, Y_training, X_validation, Y_validation)\n",
    "\n",
    "# 9 sample target values for output\n",
    "target_sample = np.array([0.72864795, 0.72025004, 0.66572048, 0.68154454, 0.65445883, 0.57947686, 0.60197869, 0.53777778, 0.56603774])\n",
    "\n",
    "#lower and upper bounds for input values. These values will be used as constraints for the optimization \n",
    "lower_bound = [1, 0.5, 5, 1, 0.4, 390]\n",
    "upper_bound = [2.5, 1, 10, 5, 0.8,760]\n",
    "\n",
    "# Use selected solver to create and solve the optimization model for given sample target values\n",
    "result = optimizer.solve_optimization(target_sample,lower_bound,upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FULL Working Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "M = pd.read_csv('testing/data/output-seed_1337-30000.csv')\n",
    "#NORMALIZATION\n",
    "M.drop(M.columns[[8,12,13,16,17,18,21]], axis = 1, inplace= True)\n",
    "for i in range(6,15):\n",
    "    M.iloc[:,i] = (M.iloc[:,i] - M.iloc[:,i].min())/(M.iloc[:,i].max() - M.iloc[:,i].min())\n",
    "    target_sample = M.sample(100)\n",
    "M = M.drop(target_sample.index)\n",
    "M.reset_index(inplace=True)\n",
    "M.drop(M.columns[0], axis = 1, inplace=True)\n",
    "M.to_csv('testing/data/OutputMinMaxScaledResults30000.csv')\n",
    "target_sample.to_csv('testing/data/TargetSample.csv')\n",
    "\n",
    "M_train = M.sample(frac=0.7,  random_state=1337)\n",
    "M_rest = M.drop(M_train.index)\n",
    "M_validation = M_rest.sample(frac=0.5,  random_state=1337)\n",
    "M_test = M_rest.drop(M_validation.index)\n",
    "\n",
    "X_training = np.array(M_train.iloc[:,:6])\n",
    "X_validation = np.array(M_validation.iloc[:,:6])\n",
    "X_test = np.array(M_test.iloc[:,:6])\n",
    "\n",
    "Y_training = np.array(M_train.iloc[:,6:])\n",
    "Y_validation = np.array(M_validation.iloc[:,6:])\n",
    "Y_test = np.array(M_test.iloc[:,6:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare target value datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "Target_Sample = pd.read_csv('testing/data/TargetSample.csv', index_col=0).iloc[:,[6,7,8,9,10,11,12,13,14]]\n",
    "Target_Sample.reset_index(inplace=True)\n",
    "Target_Sample.drop(Target_Sample.columns[0], axis = 1, inplace=True)\n",
    "target_val = np.array(Target_Sample[0:1]).tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|output: false\n",
    "#| eval: false\n",
    "\n",
    "optimizer = CalibrateSimulation(OptimizerType.OR_TOOLS)\n",
    "optimizer.train_model(X_training, Y_training, X_validation, Y_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate calibration inputs using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|output: false\n",
    "#| eval: false\n",
    "\n",
    "sample_arrays = np.array(Target_Sample)\n",
    "lower_bound = [1, 0.5, 5, 1, 0.4, 390]\n",
    "upper_bound = [2.5, 1, 10, 5, 0.8,760]\n",
    "\n",
    "results_param = {}\n",
    "results_output = {}\n",
    "for i in range(100):\n",
    "    result = optimizer.solve_optimization(sample_arrays[i],lower_bound,upper_bound)\n",
    "    results_param[i] = result[0]\n",
    "    results_output[i] = result[1]\n",
    "    print(f'{i} done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "print(results_param)\n",
    "print(results_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('calibrate-simulation')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
